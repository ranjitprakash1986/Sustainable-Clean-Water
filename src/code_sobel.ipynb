{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f9f8018-973c-479b-b2f1-d5c73a5d7239",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "import io\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import skimage\n",
    "import cv2\n",
    "\n",
    "import os\n",
    "\n",
    "# Regression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# PCA\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Additional features\n",
    "from skimage.filters.rank import entropy\n",
    "from skimage.morphology import disk\n",
    "from skimage.filters import sobel\n",
    "from scipy import ndimage as nd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e3b0838-3991-444f-99ef-47601051e87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace <BUCKET_NAME> with the name of your bucket\n",
    "bucket_name = 'biznovate_images'\n",
    "\n",
    "# Create a client object for the storage service\n",
    "client = storage.Client()\n",
    "\n",
    "\n",
    "# Get a reference to the bucket\n",
    "bucket = client.get_bucket(bucket_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e236d9b-57ba-4f6f-99ad-9f75f69348ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace <OBJECT_NAME> with the name of the object you want to read\n",
    "train_csv = 'train.csv'\n",
    "test_csv = 'test_masked.csv'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566d95a6-bf03-40e9-9f3d-9a0ce07682e7",
   "metadata": {},
   "source": [
    "## Load the Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "627f6bda-d61b-4a50-9c43-b0f3e5044007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a reference to the object\n",
    "train_blob = bucket.blob(train_csv)\n",
    "train_csv_contents = train_blob.download_as_string().decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4135a2e7-c7ba-4c07-bc8f-172945699c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the string as a pandas dataframe\n",
    "data_train = pd.read_csv(io.StringIO(train_csv_contents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a9bc69e-2fe7-417e-94d0-76b551ce14e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DHSID_EA</th>\n",
       "      <th>cname</th>\n",
       "      <th>year</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>n_asset</th>\n",
       "      <th>asset_index</th>\n",
       "      <th>n_water</th>\n",
       "      <th>water_index</th>\n",
       "      <th>cluster_id</th>\n",
       "      <th>adm1dhs</th>\n",
       "      <th>urban</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IA-2015-7-00010004</td>\n",
       "      <td>IA</td>\n",
       "      <td>2015</td>\n",
       "      <td>9.165413</td>\n",
       "      <td>92.742696</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.650768</td>\n",
       "      <td>22.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>10004</td>\n",
       "      <td>1</td>\n",
       "      <td>R</td>\n",
       "      <td>dhs_train/IA-2015-7-00010004.npz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IA-2015-7-00010005</td>\n",
       "      <td>IA</td>\n",
       "      <td>2015</td>\n",
       "      <td>8.307356</td>\n",
       "      <td>93.093792</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.157784</td>\n",
       "      <td>22.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>10005</td>\n",
       "      <td>1</td>\n",
       "      <td>R</td>\n",
       "      <td>dhs_train/IA-2015-7-00010005.npz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IA-2015-7-00010007</td>\n",
       "      <td>IA</td>\n",
       "      <td>2015</td>\n",
       "      <td>7.016968</td>\n",
       "      <td>93.893226</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.832751</td>\n",
       "      <td>21.0</td>\n",
       "      <td>4.619048</td>\n",
       "      <td>10007</td>\n",
       "      <td>1</td>\n",
       "      <td>R</td>\n",
       "      <td>dhs_train/IA-2015-7-00010007.npz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IA-2015-7-00010016</td>\n",
       "      <td>IA</td>\n",
       "      <td>2015</td>\n",
       "      <td>9.194938</td>\n",
       "      <td>92.800432</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.746096</td>\n",
       "      <td>22.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>10016</td>\n",
       "      <td>1</td>\n",
       "      <td>R</td>\n",
       "      <td>dhs_train/IA-2015-7-00010016.npz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IA-2015-7-00010018</td>\n",
       "      <td>IA</td>\n",
       "      <td>2015</td>\n",
       "      <td>8.055606</td>\n",
       "      <td>93.543892</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.581869</td>\n",
       "      <td>22.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>10018</td>\n",
       "      <td>1</td>\n",
       "      <td>R</td>\n",
       "      <td>dhs_train/IA-2015-7-00010018.npz</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             DHSID_EA cname  year       lat        lon  n_asset  asset_index  \\\n",
       "0  IA-2015-7-00010004    IA  2015  9.165413  92.742696     22.0     2.650768   \n",
       "1  IA-2015-7-00010005    IA  2015  8.307356  93.093792     22.0     2.157784   \n",
       "2  IA-2015-7-00010007    IA  2015  7.016968  93.893226     21.0     1.832751   \n",
       "3  IA-2015-7-00010016    IA  2015  9.194938  92.800432     22.0     2.746096   \n",
       "4  IA-2015-7-00010018    IA  2015  8.055606  93.543892     22.0     2.581869   \n",
       "\n",
       "   n_water  water_index  cluster_id  adm1dhs urban  \\\n",
       "0     22.0     5.000000       10004        1     R   \n",
       "1     22.0     5.000000       10005        1     R   \n",
       "2     21.0     4.619048       10007        1     R   \n",
       "3     22.0     5.000000       10016        1     R   \n",
       "4     22.0     5.000000       10018        1     R   \n",
       "\n",
       "                               path  \n",
       "0  dhs_train/IA-2015-7-00010004.npz  \n",
       "1  dhs_train/IA-2015-7-00010005.npz  \n",
       "2  dhs_train/IA-2015-7-00010007.npz  \n",
       "3  dhs_train/IA-2015-7-00010016.npz  \n",
       "4  dhs_train/IA-2015-7-00010018.npz  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10683b6b-cc83-4ea2-9dde-9000a94cd7c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>n_asset</th>\n",
       "      <th>asset_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.165413</td>\n",
       "      <td>92.742696</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.650768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.307356</td>\n",
       "      <td>93.093792</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.157784</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        lat        lon  n_asset  asset_index\n",
       "0  9.165413  92.742696     22.0     2.650768\n",
       "1  8.307356  93.093792     22.0     2.157784"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_train df after drop columns\n",
    "X_train = data_train.drop(['DHSID_EA', 'cname', 'year', 'cluster_id', 'adm1dhs', 'urban', 'path', 'water_index', 'n_water'], axis = 1)\n",
    "X_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb9aa79f-e17f-450c-903f-bf118e3b47a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5.0\n",
       "1    5.0\n",
       "Name: water_index, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_train series\n",
    "y_train = data_train['water_index']\n",
    "y_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec873eb-6654-4073-b263-e3ad6bdac37b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fec85d-c994-4593-9eb9-227d8103d6d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6ef649-4bd1-40fc-be40-015dce5c92e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ddedf8-968a-423b-a30e-20abbff60460",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9957b26e-53cf-47da-9603-cc57dea073e0",
   "metadata": {},
   "source": [
    "## Load the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "835fcdb4-8f1d-4cb5-ba53-f10f5e4f473f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a reference to the object\n",
    "test_blob = bucket.blob(test_csv)\n",
    "test_csv_contents = test_blob.download_as_string().decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24c58131-dc6f-4889-b321-a4c6eded7034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the string as a pandas dataframe\n",
    "data_test = pd.read_csv(io.StringIO(test_csv_contents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a35d8d7-322e-46a2-9a2b-f957963f1c88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DHSID_EA</th>\n",
       "      <th>cname</th>\n",
       "      <th>year</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>n_asset</th>\n",
       "      <th>asset_index</th>\n",
       "      <th>cluster_id</th>\n",
       "      <th>adm1dhs</th>\n",
       "      <th>urban</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IA-2015-7-00010009</td>\n",
       "      <td>IA</td>\n",
       "      <td>2015</td>\n",
       "      <td>9.220903</td>\n",
       "      <td>92.781530</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.721812</td>\n",
       "      <td>10009</td>\n",
       "      <td>1</td>\n",
       "      <td>R</td>\n",
       "      <td>dhs_valid/IA-2015-7-00010009.npz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IA-2015-7-00010011</td>\n",
       "      <td>IA</td>\n",
       "      <td>2015</td>\n",
       "      <td>7.028410</td>\n",
       "      <td>93.883430</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2.287279</td>\n",
       "      <td>10011</td>\n",
       "      <td>1</td>\n",
       "      <td>R</td>\n",
       "      <td>dhs_valid/IA-2015-7-00010011.npz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IA-2015-7-00010017</td>\n",
       "      <td>IA</td>\n",
       "      <td>2015</td>\n",
       "      <td>12.371448</td>\n",
       "      <td>92.783665</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.677109</td>\n",
       "      <td>10017</td>\n",
       "      <td>1</td>\n",
       "      <td>R</td>\n",
       "      <td>dhs_valid/IA-2015-7-00010017.npz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IA-2015-7-00010044</td>\n",
       "      <td>IA</td>\n",
       "      <td>2015</td>\n",
       "      <td>11.727304</td>\n",
       "      <td>92.719257</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.793683</td>\n",
       "      <td>10044</td>\n",
       "      <td>1</td>\n",
       "      <td>R</td>\n",
       "      <td>dhs_valid/IA-2015-7-00010044.npz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IA-2015-7-00010060</td>\n",
       "      <td>IA</td>\n",
       "      <td>2015</td>\n",
       "      <td>9.185310</td>\n",
       "      <td>92.777645</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.758168</td>\n",
       "      <td>10060</td>\n",
       "      <td>1</td>\n",
       "      <td>R</td>\n",
       "      <td>dhs_valid/IA-2015-7-00010060.npz</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             DHSID_EA cname  year        lat        lon  n_asset  asset_index  \\\n",
       "0  IA-2015-7-00010009    IA  2015   9.220903  92.781530     22.0     2.721812   \n",
       "1  IA-2015-7-00010011    IA  2015   7.028410  93.883430     20.0     2.287279   \n",
       "2  IA-2015-7-00010017    IA  2015  12.371448  92.783665     22.0     0.677109   \n",
       "3  IA-2015-7-00010044    IA  2015  11.727304  92.719257     21.0     1.793683   \n",
       "4  IA-2015-7-00010060    IA  2015   9.185310  92.777645     22.0     2.758168   \n",
       "\n",
       "   cluster_id  adm1dhs urban                              path  \n",
       "0       10009        1     R  dhs_valid/IA-2015-7-00010009.npz  \n",
       "1       10011        1     R  dhs_valid/IA-2015-7-00010011.npz  \n",
       "2       10017        1     R  dhs_valid/IA-2015-7-00010017.npz  \n",
       "3       10044        1     R  dhs_valid/IA-2015-7-00010044.npz  \n",
       "4       10060        1     R  dhs_valid/IA-2015-7-00010060.npz  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2c4300a-e302-4496-8327-8ff62d177273",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>n_asset</th>\n",
       "      <th>asset_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.220903</td>\n",
       "      <td>92.78153</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.721812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.028410</td>\n",
       "      <td>93.88343</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2.287279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        lat       lon  n_asset  asset_index\n",
       "0  9.220903  92.78153     22.0     2.721812\n",
       "1  7.028410  93.88343     20.0     2.287279"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_train df after drop columns\n",
    "X_test = data_test.drop(['DHSID_EA', 'cname', 'year', 'cluster_id', 'adm1dhs', 'urban', 'path'], axis = 1)\n",
    "X_test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53b0d2d-8876-454e-b2c3-75542ca5617e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34b98f6-fbb5-4170-98f4-3f32d1d86141",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be3d00cc-7d1b-411d-826f-a346dd8ffb1e",
   "metadata": {},
   "source": [
    "# Basic regression for establishing baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c3a2b29-0f18-4100-9626-352beee9963d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to run ridgecv\n",
    "\n",
    "def ridgecv(X_train, y_train):\n",
    "    X_tr, X_cv, y_tr, y_cv = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "    \n",
    "    pipeline = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    RidgeCV(alphas=[0.1, 1.0, 10.0, 100.0], cv = 5)\n",
    "    )\n",
    "\n",
    "    model = pipeline.fit(X_tr, y_tr)\n",
    "\n",
    "    print(\"Optimal alpha: {}\".format(model.named_steps['ridgecv'].alpha_))\n",
    "    print(\"R^2 score: {:.2f}\".format(model.score(X_cv, y_cv)))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1bdbd7-a519-4fc0-8a6f-df1bf5c742a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7881b57b-719c-40f1-aab8-cc85d216c7ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal alpha: 1.0\n",
      "R^2 score: 0.55\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('ridgecv',\n",
       "                 RidgeCV(alphas=array([  0.1,   1. ,  10. , 100. ]), cv=5))])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baseline regression on initial columns\n",
    "\n",
    "ridgecv(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1b0d7e-2efd-4a7a-8060-a1a4d75593e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4555963d-f234-4cec-9302-e8cefaf2506d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf(X_train, y_train):\n",
    "    X_tr, X_cv, y_tr, y_cv = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "    \n",
    "    pipeline = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    )\n",
    "\n",
    "    model = pipeline.fit(X_tr, y_tr)\n",
    "\n",
    "    print(\"R^2 score: {:.2f}\".format(model.score(X_cv, y_cv)))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e80709e-4225-478e-8d51-a91ff8a2b39c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 score: 0.72\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('randomforestregressor',\n",
       "                 RandomForestRegressor(random_state=42))])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b861fb7-5bba-4be5-b2cc-df2ab11f2157",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d8160aca-ccb5-4901-998f-25a5ba7c23f0",
   "metadata": {},
   "source": [
    "## Converting each image band to features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa278bc-8952-41eb-9e90-d9ea17906c2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc96f47-1716-412d-b5ab-b19417eb9d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to read the pixels in band and append as feature to the data_train\n",
    "\n",
    "def read_featurize(df, band = 0, file=1):\n",
    "    ''' Flatten specified image and band to numpy array'''\n",
    "    object_name = df['path'][file]\n",
    "    \n",
    "    # Get a reference to the object\n",
    "    blob = bucket.blob(object_name)\n",
    "    \n",
    "    npz_bytes = blob.download_as_bytes()\n",
    "    img = np.load(io.BytesIO(npz_bytes))['x']\n",
    "    \n",
    "    return (img[band,].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98b1442-4252-4eb6-9755-4c592518de36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "53dec9a7-b775-4c69-8614-01a28c89f8f6",
   "metadata": {},
   "source": [
    "## Flatten the each band and do the PCA on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab7d07d-c926-493b-9472-d951908a4c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "band_num=4\n",
    "# initialize the feature numpy or the len 255*255\n",
    "band_feat = np.zeros((data_train.shape[0], 255*255))\n",
    "test_band_feat = np.zeros((data_test.shape[0], 255*255))\n",
    "\n",
    "for index in range(data_train.shape[0]):\n",
    "    band_feat[index] = read_featurize(data_train, band_num, index)\n",
    "\n",
    "for index in range(data_test.shape[0]):\n",
    "    test_band_feat[index] = read_featurize(data_test, band_num, index)\n",
    "\n",
    "# For each band in the image make a feature matrix for all 18K train images\n",
    "# standardize and transform train \n",
    "scaler = StandardScaler()\n",
    "scaler.fit(band_feat)\n",
    "band_feat_std = scaler.transform(band_feat)\n",
    "\n",
    "# transform test\n",
    "test_band_feat_std = scaler.transform(test_band_feat)\n",
    "\n",
    "# pca with 3 components fit and transform train\n",
    "pca = PCA(n_components=n_comp)\n",
    "pca.fit(band_feat_std)\n",
    "\n",
    "variable = \"band_feat_pca\"\n",
    "result[variable] = pca.transform(band_feat_std)\n",
    "\n",
    "# pca with 3 components transform test\n",
    "variable = \"test_band_feat_pca\"\n",
    "test_result[variable] = pca.transform(test_band_feat_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07007c7-999f-449f-ae8b-52d7f97b4ebf",
   "metadata": {},
   "source": [
    "## Create the feature numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdeb7338-3a1b-4afb-b8df-4a5c2ff516a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_np = X_train.to_numpy()\n",
    "X_test_np = X_test.to_numpy()\n",
    "\n",
    "X_train_band_pca = np.concatenate((\n",
    "    X_train_np,\n",
    "    result['band_feat_pca0'],\n",
    "    result['band_feat_pca1'],\n",
    "    result['band_feat_pca2'],\n",
    "    result['band_feat_pca3'],\n",
    "    result['band_feat_pca4'],\n",
    "    result['band_feat_pca5'],\n",
    "    result['band_feat_pca6'],\n",
    "    result['band_feat_pca7']\n",
    "), axis = 1)\n",
    "\n",
    "\n",
    "X_test_band_pca = np.concatenate((\n",
    "    X_test_np,\n",
    "    test_result['test_band_feat_pca0'],\n",
    "    test_result['test_band_feat_pca1'],\n",
    "    test_result['test_band_feat_pca2'],\n",
    "    test_result['test_band_feat_pca3'],\n",
    "    test_result['test_band_feat_pca4'],\n",
    "    test_result['test_band_feat_pca5'],\n",
    "    test_result['test_band_feat_pca6'],\n",
    "    test_result['test_band_feat_pca7']\n",
    "), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af90d10-8dba-4a2d-8447-4dd5a921a9f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e55354cf-b616-4c38-a55e-af8262387480",
   "metadata": {},
   "source": [
    "## Ridge Regression on the feature numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ab8338-5506-46fe-a5cf-5cc69c69ae02",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridgecv(X_train_band_pca, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddbf410-b074-4443-b60a-e399f1b2cfc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4f05e110-a374-4202-870f-4069210d069a",
   "metadata": {},
   "source": [
    "## Random forrest Regression on the feature numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3f4663-828b-4caf-99d5-eeb6adad5fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf(X_train, y_train):\n",
    "    X_tr, X_cv, y_tr, y_cv = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "    \n",
    "    pipeline = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    )\n",
    "\n",
    "    model = pipeline.fit(X_tr, y_tr)\n",
    "\n",
    "    print(\"R^2 score: {:.2f}\".format(model.score(X_cv, y_cv)))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fa093d-b99c-4ea5-8344-94740c10859a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf(X_train_band_pca, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2e6bac-b128-49b6-ae8c-aa4f5a077ffb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ae2c01-a23f-4c13-897c-147bfca59c38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6809259b-7cda-46e2-bd09-c4a1f7bd4c72",
   "metadata": {},
   "source": [
    "## Adding Sobel feature, band 5 only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d5e959a4-3842-4b71-b2b3-94078038871a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sobel_filter(df, file=1, band = 4):\n",
    "    ''' add filter and features the the image only using one band\n",
    "        Gaussian and Enropy commented out and may be tried if required\n",
    "    '''\n",
    "    object_name = df['path'][file]\n",
    "    \n",
    "    # Get a reference to the object\n",
    "    blob = bucket.blob(object_name)\n",
    "    \n",
    "    npz_bytes = blob.download_as_bytes()\n",
    "    img = np.load(io.BytesIO(npz_bytes))['x']\n",
    "    img = np.uint8(img*255) # changing to uint8\n",
    "    \n",
    "\n",
    "    # Entropy image\n",
    "    # entropy_img = np.round(entropy(img[4,], disk(1)),2)\n",
    "\n",
    "    # Gaussian image\n",
    "    # gaussian_img = np.round(nd.gaussian_filter(img[4,], sigma = 1),2)\n",
    "\n",
    "    # Sobel image\n",
    "    sobel_img = np.round(sobel(img[band,]),2)\n",
    "    return sobel_img.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3bc396c0-142b-4738-849c-7049e7b472e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aef15150-c087-4e4b-9be8-99321c97613e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and write the sobel feature image for each train image\n",
    "\n",
    "# initialize the feature numpy or the len 255*255\n",
    "sobel_feat = np.zeros((data_train.shape[0], 255*255))\n",
    "test_sobel_feat = np.zeros((data_test.shape[0], 255*255))\n",
    "\n",
    "for index in range(data_train.shape[0]):\n",
    "    sobel_feat[index] = sobel_filter(data_train, index)\n",
    "\n",
    "\n",
    "for index in range(data_test.shape[0]):\n",
    "    test_sobel_feat[index] = sobel_filter(data_test, index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98679d1-ddc4-41ea-bee6-46318a76ecf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bc8d4dc6-f4a7-45ba-baf0-ed778ba65797",
   "metadata": {},
   "source": [
    "### PCA for Sobel features band 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e4d9cf0c-3119-4bf2-bba3-7b85615d74ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize fit and transform on train\n",
    "sobel_scaler = StandardScaler().fit(sobel_feat)\n",
    "sobel_feat_std = sobel_scaler.transform(sobel_feat)\n",
    "\n",
    "# transform on test\n",
    "test_sobel_feat_std = sobel_scaler.transform(test_sobel_feat)\n",
    "\n",
    "# pca fit and transform on train\n",
    "ncomp = 3\n",
    "sobel_pca = PCA(n_components=ncomp)\n",
    "sobel_pca.fit(sobel_feat_std)\n",
    "sobel_pca_transformed = sobel_pca.transform(sobel_feat_std)\n",
    "\n",
    "# pca transform on test\n",
    "test_sobel_pca_transformed = sobel_pca.transform(test_sobel_feat_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce323e7-9b34-445e-aa37-f2ad4322c095",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e3685475-6506-4f36-9c02-1f12d9f550e9",
   "metadata": {},
   "source": [
    "## Concatenate with sobel features for band 5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c31183a9-9664-496f-99c3-a3bed6fd167b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_np = X_train.to_numpy()\n",
    "X_test_np = X_test.to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "56c15bfa-9664-4dd6-8cb8-6054b6d808da",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_band_sobel_pca = np.concatenate((\n",
    "    X_train_np,\n",
    "    sobel_pca_transformed\n",
    "), axis = 1)\n",
    "\n",
    "X_test_band_sobel_pca = np.concatenate((\n",
    "    X_test_np,\n",
    "    test_sobel_pca_transformed\n",
    "), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6257d2e6-ff9f-421b-8b90-f922ea4e76b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "afaaabb2-7627-4798-a183-73ab3792f3c2",
   "metadata": {},
   "source": [
    "## Add entropy filter band 5 only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f480d25b-2990-4423-9f16-e4a3a937114b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy_filter(df, file=1, band = 4):\n",
    "    ''' add entropy filter features on the image only using one band\n",
    "    '''\n",
    "    object_name = df['path'][file]\n",
    "    \n",
    "    # Get a reference to the object\n",
    "    blob = bucket.blob(object_name)\n",
    "    \n",
    "    npz_bytes = blob.download_as_bytes()\n",
    "    img = np.load(io.BytesIO(npz_bytes))['x']\n",
    "    img = np.uint8(img*255) # changing to uint8\n",
    "    \n",
    "\n",
    "    # Entropy image\n",
    "    entropy_img = np.round(entropy(img[band,], disk(1)),2)\n",
    "\n",
    "    # Gaussian image\n",
    "    # gaussian_img = np.round(nd.gaussian_filter(img[band,], sigma = 1),2)\n",
    "\n",
    "    # Sobel image\n",
    "    # sobel_img = np.round(sobel(img[band,]),2)\n",
    "    return entropy_img.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f6201d65-d800-447d-affd-dbd42408b933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and write the entropy feature image for each train image\n",
    "\n",
    "# initialize the feature numpy or the len 255*255\n",
    "entropy_feat = np.zeros((data_train.shape[0], 255*255))\n",
    "test_entropy_feat = np.zeros((data_test.shape[0], 255*255))\n",
    "\n",
    "for index in range(data_train.shape[0]):\n",
    "    entropy_feat[index] = entropy_filter(data_train, index)\n",
    "\n",
    "\n",
    "for index in range(data_test.shape[0]):\n",
    "    test_entropy_feat[index] = entropy_filter(data_test, index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13500377-e668-4c33-a008-9a7e25d43117",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7e3c03e4-07b9-44f9-aa69-a5de5fb5717b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2816"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b9d4a734-7708-4046-be70-6801e3d353eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "del sobel7_pca_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a7535e08-0318-4724-800f-837db22f557a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ae4a07-627b-4902-a9e2-ac6a49b3e7e1",
   "metadata": {},
   "source": [
    "### PCA with entropy on band 5 only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7bd41dfc-b7b7-4d86-847c-ee374c014eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy_feat = entropy_feat.astype(np.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2ddc05f8-f3f5-4fec-9915-6ef8feb91285",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_entropy_feat = test_entropy_feat.astype(np.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2d4103e8-3b9b-4bcc-be70-5c916b23c897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize fit and transform on train\n",
    "entropy_scaler = StandardScaler().fit(entropy_feat)\n",
    "entropy_feat_std = entropy_scaler.transform(entropy_feat)\n",
    "entropy_feat_std = entropy_feat_std.astype(np.float16)\n",
    "\n",
    "# transform on test\n",
    "test_entropy_feat_std = entropy_scaler.transform(test_entropy_feat)\n",
    "test_entropy_feat_std = test_entropy_feat_std.astype(np.float16)\n",
    "\n",
    "# pca fit and transform on train\n",
    "ncomp = 3\n",
    "entropy_pca = PCA(n_components=ncomp)\n",
    "entropy_pca.fit(entropy_feat_std)\n",
    "entropy_pca_transformed = entropy_pca.transform(entropy_feat_std)\n",
    "\n",
    "# pca transform on test\n",
    "test_entropy_pca_transformed = entropy_pca.transform(test_entropy_feat_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211880c9-0e91-432d-9ba6-86042ba41226",
   "metadata": {},
   "source": [
    "## Concatenate results from entropy band 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "02838949-59ef-4b9f-b4a4-df60a033043b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sobel_entropy_pca = np.concatenate((\n",
    "    X_train_band_sobel_pca,\n",
    "    entropy_pca_transformed\n",
    "), axis = 1)\n",
    "\n",
    "X_test_sobel_entropy_pca = np.concatenate((\n",
    "    X_test_band_sobel_pca,\n",
    "    test_entropy_pca_transformed\n",
    "), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccff7048-2c56-48fc-8828-b755fdb66cc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298ef86a-3f61-4a8e-a435-1a3c854f1369",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3a629e8f-692e-4c20-9dde-63a3ce407d5a",
   "metadata": {},
   "source": [
    "## Adding Sobel feature, band 7 only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "95f4bc0e-b3f5-43f6-9c0b-e53a52b240e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create and write the sobel feature image for each train image\n",
    "\n",
    "# # initialize the feature numpy or the len 255*255\n",
    "# sobel_feat = np.zeros((data_train.shape[0], 255*255))\n",
    "# test_sobel_feat = np.zeros((data_test.shape[0], 255*255))\n",
    "\n",
    "# for index in range(data_train.shape[0]):\n",
    "#     sobel_feat[index] = sobel_filter(data_train, index, band = 6)\n",
    "\n",
    "# for index in range(data_test.shape[0]):\n",
    "#     test_sobel_feat[index] = sobel_filter(data_test, index, band = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8bbd22-b12e-462b-b3a7-423159f794a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380b5219-7162-44e6-a46c-6bb9c5926c34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1d8ab0-4737-4d9f-b36c-d0e4c0547ebc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db421ee7-6d6e-473d-8347-9e01483837bd",
   "metadata": {},
   "source": [
    "### PCA with sobel band 7 only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d347c62e-ca2c-497a-8465-b0bfa9cb432b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # standardize fit and transform on train\n",
    "# sobel_scaler = StandardScaler().fit(sobel_feat)\n",
    "# sobel_feat_std = sobel_scaler.transform(sobel_feat)\n",
    "\n",
    "# # transform on test\n",
    "# test_sobel_feat_std = sobel_scaler.transform(test_sobel_feat)\n",
    "\n",
    "# # pca fit and transform on train\n",
    "# ncomp = 3\n",
    "# sobel_pca = PCA(n_components=ncomp)\n",
    "# sobel_pca.fit(sobel_feat_std)\n",
    "# sobel7_pca_transformed = sobel_pca.transform(sobel_feat_std)\n",
    "\n",
    "# # pca transform on test\n",
    "# test_sobel7_pca_transformed = sobel_pca.transform(test_sobel_feat_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ed9e01-ef77-4b4b-bd88-55c907da7222",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b3035814-fc19-44f4-9299-ee91ee749181",
   "metadata": {},
   "source": [
    "## Concatenate results from Sobel band 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e13d2b2-9e54-497c-adc3-2bada71e19de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fa2dfcbb-0ce6-4de3-8df5-444070b532fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_band5_band7_sobel_pca = np.concatenate((\n",
    "#     X_train_band_sobel_pca,\n",
    "#     sobel7_pca_transformed\n",
    "# ), axis = 1)\n",
    "\n",
    "# X_test_band5_band7_sobel_pca = np.concatenate((\n",
    "#     X_test_band_sobel_pca,\n",
    "#     test_sobel7_pca_transformed\n",
    "# ), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb48072-2e05-4845-be4c-eb29bd889bbe",
   "metadata": {},
   "source": [
    "## Regression models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b0967c31-7658-4666-a07c-46691b00d6d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 score: 0.71\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('randomforestregressor',\n",
       "                 RandomForestRegressor(random_state=42))])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf(X_train_sobel_entropy_pca, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a35e9a-e6f1-41a2-a1bc-fe07bfcbd47d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc528efa-5175-4592-9b5c-15f431f97992",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "bdc29762-8abd-4f8d-b432-7744ddb27d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = make_pipeline(\n",
    "StandardScaler(),\n",
    "RandomForestRegressor(n_estimators=100, random_state=42)\n",
    ")\n",
    "\n",
    "model = pipeline.fit(X_train_sobel_entropy_pca, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "fe8deac9-f539-4c48-9bc5-f00c098be30f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.88489952, 4.6768248 , 4.5311093 , ..., 4.84791988, 4.25078868,\n",
       "       4.40306912])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test_sobel_entropy_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8e8ad69e-6991-41d0-8ef2-99312f92d7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test_sobel_entropy_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "fca14617-46a7-473d-a6ac-187899c0b449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       IA-2015-7-00010009\n",
       "1       IA-2015-7-00010011\n",
       "2       IA-2015-7-00010017\n",
       "3       IA-2015-7-00010044\n",
       "4       IA-2015-7-00010060\n",
       "               ...        \n",
       "2670    IA-2015-7-00360403\n",
       "2671    IA-2015-7-00360454\n",
       "2672    IA-2015-7-00360474\n",
       "2673    IA-2015-7-00360476\n",
       "2674    IA-2015-7-00360479\n",
       "Name: DHSID_EA, Length: 2675, dtype: object"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test['DHSID_EA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "22451018-7ed3-4ce5-babe-9b60a5243590",
   "metadata": {},
   "outputs": [],
   "source": [
    "final = data_test.assign(water_index = y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8374b462-b5a9-42cd-9467-6c0d34c23e0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['DHSID_EA', 'cname', 'year', 'lat', 'lon', 'n_asset', 'asset_index',\n",
       "       'cluster_id', 'adm1dhs', 'urban', 'path', 'water_index'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef4d769-97ed-4a90-b099-dc25b0c22c7f",
   "metadata": {},
   "source": [
    "# Exporting the csv file to bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a49649e4-98c0-428b-9f94-2f4d69245a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "contents_csv = final[['DHSID_EA','water_index']].to_csv(index = False)\n",
    "\n",
    "csv_bytes = bytes(contents_csv, 'utf-8')\n",
    "\n",
    "blob = bucket.blob('final_sobel_entropy_csv')\n",
    "blob.upload_from_string(csv_bytes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2788ab3a-877b-4414-90e2-af65361cafd6",
   "metadata": {},
   "source": [
    "### Export feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "903a7e31-8ce6-4904-8550-dceb6fed4315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_csv = pd.DataFrame(X_train_sobel_entropy_pca).to_csv(index=False)\n",
    "# csv_bytes = bytes(feature_csv, 'utf-8')\n",
    "# blob = bucket.blob('feature_sobel_entropy_train_csv')\n",
    "# blob.upload_from_string(csv_bytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d506ad7c-1425-417b-acc8-22626d66477f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_test_csv = pd.DataFrame(X_test_sobel_entropy_pca).to_csv(index=False)\n",
    "# csv_bytes = bytes(feature_test_csv, 'utf-8')\n",
    "# blob = bucket.blob('feature_sobel_entropy_test_csv')\n",
    "# blob.upload_from_string(csv_bytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc0e447-2ee1-4ed3-8a52-e1d5fc212a8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m104",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m104"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
